{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaf4886",
   "metadata": {},
   "source": [
    "## 5 Pretraining on unlabeled data\n",
    "\n",
    "### 5.1 Evaluating generative text models\n",
    "\n",
    "#### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137fdec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.7\n",
      "numpy version: 2.3.4\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.0\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import previous_chapters\n",
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\" # for openAI's pretrained weights\n",
    "        ]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0e7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, # Context size reduced for better performance\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5fbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "model.eval(); # inference/pred mode to suppress randomness\n",
    "# SEMICOLON SUPPRESSES OUTPUT (otherwise the model architechture is printed)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee2b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "# Convert text to token ids\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add a dimension for batching\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1325f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = text_to_token_ids(start_context, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3122568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from tiktoken import Encoding\n",
    "\n",
    "def token_ids_to_text(token_ids: Tensor, tokenizer: Encoding):\n",
    "    flat = token_ids.squeeze(0) # remove batching dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "    # tiktoken works with python lists, so the argument for the decode function needs to be a list as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21603fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea4234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472dfae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
       "          5308,  3398, 13174, 43071]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e73e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you rentingetic wasnم refres RexMeCHicular stren'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5ea07",
   "metadata": {},
   "source": [
    "Again, nonsense output because no training was done. Without training, we cannot determine how accurate generated text is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736eb061",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf37c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],\n",
    "                        [40, 1107, 588]])\n",
    "\n",
    "# [\"every effort moves\", <- first input\n",
    "#  \"I really like\"] <- second input\n",
    "# this is a batch of two inputs\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],\n",
    "                        [1107, 588, 11311]])\n",
    "\n",
    "# [\"effort moves you\", <- first target output\n",
    "#  \"really like chocolate\"] <- second target output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee1d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de773e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d5232",
   "metadata": {},
   "source": [
    "2 rows, each row has 3 tokens, and each of the logits is a 50257 length vector corresponding to likelihoods of each vocab word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070f9044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.softmax(logits, dim=-1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23dc6819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
       "          6.9776e-06, 1.8776e-05],\n",
       "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
       "          6.0103e-06, 1.3571e-05],\n",
       "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
       "          1.4094e-05, 1.3526e-05]],\n",
       "\n",
       "        [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
       "          3.4784e-05, 1.4239e-05],\n",
       "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
       "          1.1390e-05, 1.5559e-05],\n",
       "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
       "          5.8203e-05, 1.3698e-05]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "831c8f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16657,   339, 42826],\n",
       "        [49906, 29669, 41751]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.argmax(preds, dim=-1, keepdim=False)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "859c9169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets Batch 1:  effort moves you\n",
      "Preds Batch 1:    Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets Batch 1: {token_ids_to_text(targets[0:1, :], tokenizer)}\")\n",
    "\n",
    "print(f\"Preds Batch 1:   {token_ids_to_text(token_ids[0:1, :], tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d5240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1:  tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n"
     ]
    }
   ],
   "source": [
    "target_probas1 = preds[0, [0, 1, 2], targets[0]]\n",
    "print(\"Text 1: \", target_probas1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89ae4e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 2:  tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "target_probas2 = preds[1, [0, 1, 2], targets[1]]\n",
    "print(\"Text 2: \", target_probas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0cb4620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.cat((target_probas1, target_probas2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "509a1dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities:  tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas1, target_probas2)))\n",
    "print(\"Log probabilities: \", log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5942dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*torch.mean(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288fb36",
   "metadata": {},
   "source": [
    "Above is the cross entropy loss. We want to get this as close to zero as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2ea305c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "logits_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7683e",
   "metadata": {},
   "source": [
    "This basically does the torch cat that we did earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a6197a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_flat = targets.flatten()\n",
    "targets_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e87d824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae72d5",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d411abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86481531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03ccbb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_chars = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters: \", total_chars)\n",
    "print(\"Tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15e425",
   "metadata": {},
   "source": [
    "Need to make a train-test split to actually train the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a301b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 6 tokens become the first training sample,\n",
    "# the next 6 tokens become the second training sample, and so on.\n",
    "\n",
    "# then we group samples into batches for training (batch size 2 here)\n",
    "\n",
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "652023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True, # drop last incomplete batch\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e20a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea8136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "575c0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel() # numel -> num elements\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "913e572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch : Tensor, target_batch : Tensor, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else: \n",
    "        # reduce num batches to match the total num of batches in the data loader if num batches exceeds that in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):    \n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d009545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab75cf90",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m torch.manual_seed(\u001b[32m123\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(): \u001b[38;5;66;03m# disable gradient tracking for efficiency because we are not training yet\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# to prevent tensor misalignment\u001b[39;00m\n\u001b[32m      5\u001b[39m     train_loss = calc_loss_loader(train_loader, model, device)\n\u001b[32m      6\u001b[39m     val_loss = calc_loss_loader(val_loader, model, device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sidd\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sidd\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sidd\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sidd\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sidd\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad(): # disable gradient tracking for efficiency because we are not training yet\n",
    "    model.to(\"cuda\") # to prevent tensor misalignment\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec78225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(59130.3828)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perplexity\n",
    "torch.exp(torch.tensor(10.9875))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac05b28",
   "metadata": {},
   "source": [
    "the perplexity kind of tells us how many words the model is unsure about in the vocabulary. Here, it is greater than the actual vocab size, indicating that the model is basically completely untrained (which it is)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d5fbf",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device) # cross-entropy loss\n",
    "            loss.backward() # calc loss gradients\n",
    "            optimizer.step() # update model weights using loss gradients (SGD, Adam, etc)\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # optional eval step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "                \n",
    "            # Print sample text after each epoch\n",
    "            generate_and_print_sample(\n",
    "                model, tokenizer, device, start_context\n",
    "            )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) #using adam here (could use SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682073f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.926\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you,.                                                \n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you, the,, the the the the the,,,,, the,,,, the,,,,, the the,, the,, the the the,, the the the, the the the the,,,,,\n",
      "Ep 1 (Step 000005): Train loss 8.068, Val loss 8.340\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Every effort moves you, the, the the the the the the the the the the the the the the the the the the the the the                          \n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.054\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you, the, the the the, the the the, I, the the, I, the the, I, I, the the, I the, I, the, I, the the the, the the the the, the, the the\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the, the the the the the, the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000015): Train loss 6.043, Val loss 6.601\n",
      "Every effort moves you, the, the the the, the, the, the.                                     \n",
      "Every effort moves you, the, the to the, the, the, the.                                     \n",
      "Every effort moves you, and,, and,, the,,,, and,.                                   \n",
      "Every effort moves you, and, and, and, and, and, and, and, and,, and,, and, and, and, and, and, and, and,, and, and,, and, and,, and,, and\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 3 (Step 000020): Train loss 5.509, Val loss 6.564\n",
      "Every effort moves you, and, and the a, and the a, and the of the a.                                 \n",
      "Every effort moves youNESSNESSNESSNESSNESSNESSConsidering Finding FindingきNESSNESSConsidering Finding FindingNESSNESSConsideringNESSNESSNESSNESSConsidering Finding Scoutsきき ScoutsきNESSNESSConsideringConsideringNESSNESSNESSConsidering Findingき FindingきききNESSConsideringNESSNESSきConsideringNESS\n",
      "Every effort moves you.                                                 \n",
      "Every effort moves you the a's the of the of the his-- the's.                                     \n",
      "Every effort moves you his a's the a--I--I-- the's.                                     \n",
      "Ep 3 (Step 000025): Train loss 5.346, Val loss 6.392\n",
      "Every effort moves you, and to the of the of the picture to the picture.                                     \n",
      "Every effort moves you, and to the to the of the picture to the picture.                                     \n",
      "Every effort moves you.                                                 \n",
      "Every effort moves you.                                                 \n",
      "Every effort moves you. I was. I was. I was-- the of the of the of the of the of the of the of the of the to the the of the of the to the of the the of the of the of the of the of the of\n",
      "Ep 4 (Step 000030): Train loss 4.719, Val loss 6.248\n",
      "Every effort moves you. I was. I was a--I was his I had been. I had been--I was--I     \"I, and I had been--and it. I had the picture and I had been he was his\n",
      "Every effort moves you, and I had been the picture. I was, and I had been a, and I had been, and I was, and he was a, and I had been, and he was, and I had been--and, and he was\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Every effort moves you.  \"I had been.  \"I had been. \"I had been, and I had been.  \"I had been the picture to \"I had been to the picture and I had been. \"\n",
      "Every effort moves you.  \"I \"I had been the picture.         \"   \"I had the  \"I\"I had been the \"I\"I   \"I had\n",
      "Ep 4 (Step 000035): Train loss 4.727, Val loss 6.359\n",
      "Every effort moves you of the \"I the picture.  \"I had the of the          \"I had the picture and I had been the donkey of the \"I\"I had been the picture\"I\n",
      "Every effort moves you of the picture.  \"I was the the picture. \"I\"I was the picture--and   \"I was the picture and I had been the donkey of the honour of the picture and I had been the picture of\n",
      "Every effort moves you know the      \"I the picture.               \"I\"II\"II him--and it to the donkey and I was.   \n",
      "Every effort moves you know one of the picture.                                            \n",
      "Every effort moves you know one of the picture.                                            \n",
      "Ep 5 (Step 000040): Train loss 3.869, Val loss 6.129\n",
      "Every effort moves you know the                                                \n",
      "Every effort moves you know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you know,,, and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you know, and, and pushed one of the fact, and I had been him.        \"Oh, and I felt to me, and, and in the fact of the donkey, and in the fact of the\n",
      "Every effort moves you know the \"Oh, and he had to the fact of the last word.     \"Oh, and to see. \"Oh, and he had been. \"Oh, and in the fact--I had been\n",
      "Ep 6 (Step 000045): Train loss 3.554, Val loss 6.198\n",
      "Every effort moves you know the \"Oh, and he had to the fact by the last word.        \"Oh, and I felt back the fact me, and he had been his pictures, and down the room, and in\n",
      "Every effort moves you know the        \"I had the last word.                   \"--I had the donkey, and the     \n",
      "Every effort moves you know the                                                \n",
      "Every effort moves you know the fact, and pushed one of the fact, and Mrs.              \"I, and I had always, and in the fact, and, and down the room, and in\n",
      "Every effort moves you know,\" was not to the picture. Gisburn's by his last word. Gisburn's an the fact of the fact of Jack's it was his pictures he had always about the fact of the fact of the fact--I had been\n",
      "Ep 6 (Step 000050): Train loss 3.037, Val loss 6.135\n",
      "Every effort moves you know,\" was not to the picture. Gisburn's by his last word. Gisburn's an the fact of the fact of the end of his pictures--I had always about the fact of the fact of the fact--I had been\n",
      "Every effort moves you know it was not to the picture.  \"I had the last word.                   \"I turned, and a little the man of the picture. \n",
      "Every effort moves you know the fact, and pushed one of the to the fact by his last word.                                 \n",
      "Every effort moves you know the fact, and pushed one of the--I-chairs.                                    \n",
      "Every effort moves you know the was his pictures--I glanced after him, and Mrs.                      \"Oh, I had the donkey, and I had a little of\n",
      "Ep 7 (Step 000055): Train loss 2.901, Val loss 6.116\n",
      "Every effort moves you know,\" was not that, and he was not the fact with a little a little: \"Yes, and in fact, and in a little the moment--as Jack himself, and he had not to the donkey.      \n",
      "Every effort moves you know,\" was not that, and he had to the fact with a little a little: \"Yes, and in fact of the Riv to the end of his pictures--as, and he had not to see the picture--the, and in his\n",
      "Every effort moves you know,\" was not that, and he was to the fact with a little a little: \"Yes, and in fact of the Riv to the picture. \"--the at my elbow and as he had been the man of the hour. \n",
      "Every effort moves you know,\" was not that, and he was to the fact with a little a little: \"Yes, and in fact of the Riv to the picture. \"--as he had the picture was his pictures--the \"There were days, and\n",
      "Every effort moves you know; and in a little to have to me, and I was not--so it was no I was to me to have been to the picture, and I had been at my elbow and as I was not, and I had been with your\n",
      "Ep 7 (Step 000060): Train loss 2.157, Val loss 6.124\n",
      "Every effort moves you know; and my dear--I glanced after him, and I was one of the house.\"      \"I didn't say, and I had a little. \"Be's his pictures, and down the room, I was\n",
      "Every effort moves you know; and my dear--I glanced after him, I had the last word.                   \"--and I, the donkey, and I was a little his\n",
      "Every effort moves you know,\" was one of the picture--I felt it--as of Jack's not till, I was, the fact, the fact that, I was his pictures.                \n",
      "Every effort moves you know,\" was one of the picture for a smile that he had been in a so that he was a--and here are the fact that, I was his pictures.                \n",
      "Every effort moves you know,\" was one of the picture for a smile that he had been in a so that he was a note!         He placed them at my elbow and I saw that, and down the room, I had\n",
      "Ep 8 (Step 000065): Train loss 1.739, Val loss 6.181\n",
      "Every effort moves you know,\" was one of the picture for a smile that he had been. \"I looked up, and!  \"I looked. \"I turned. \"I had been his own the donkey. \"I didn't say\n",
      "Every effort moves you know,\" was one of the ax he was he had been. \"Oh, and he was, and!  \"I looked, and he had the fact my dear, and his painting, and I was the fact--I had been\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain. \"Oh, and I was, one of Jack's the man of the moment--as Jack himself, and he was his own the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked--I looked up, I had to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked--I looked up, I had to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 8 (Step 000070): Train loss 1.442, Val loss 6.199\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked--I looked up, I had to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain. \"Oh, and--I looked up, I had been through my work of his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, and Mrs. I remember getting off a prod, as once one had been the donkey. \"There were days when I\n",
      "Every effort moves you?\" \"I that my hostess was \"interesting\": on the last word. Gisburn's an awful simpleton, and Mrs. I was back his head to look up at the honour being _mine_--because he had always _\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. Gisburn's it was no great, and in an unusual degree to the display of his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.102, Val loss 6.248\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, and Mrs. I was back the head to look up at the honour being _mine_--because he's I had\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's past!  He laughed again, I was back the head to look up at the honour being _mine_--because he's I had\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's past!  He laughed again, I remember getting off a prodigious phrase about the honour being _mine_--because he's. The\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  \"Oh, I was a back the window-curtains, I had the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. \"--and that one longed to cry out of the moment--as Jack himself, and; and continued to wander up and down the room, I had\n",
      "Ep 9 (Step 000080): Train loss 0.832, Val loss 6.285\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.        He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Victor Grindle was, in fact, and that, and the moment--as Jack himself, and \"It's his the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. Victor Grindle was, in fact, and that, in the moment--as Jack himself at theains, I saw that, and down the room, in his\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. \"Oh, and went on groping and Mrs. \"Oh, I saw that he had again run over from me. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.593, Val loss 6.374\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. \"Oh, and went on groping and Mrs. \"Oh, and he had married her--the quality of looking cleverer than he was.\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. She--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. Victor Grindle was, in fact, and that, and the moment--as Jack himself, one might put it, had been the man of the hour. The\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton, and muddling; then I looked at the donkey again. I saw that, and down the room, when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton, and muddling; then I looked at the donkey again. I saw that, the man of the hour. The\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be2e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle = \"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny() # Create a second x axis that shares the same y axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) # invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout() # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44fccf",
   "metadata": {},
   "source": [
    "The model actually began overfitting quite quickly and wasn't able to predict well on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e3ab9",
   "metadata": {},
   "source": [
    "### 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7e447",
   "metadata": {},
   "source": [
    "We usually want some randomness in the text; as things stand, the generated text actually contains direct excerpts from the original training text verbatim as a result of overfitting and picking the ARGMAX token to generate. \n",
    "\n",
    "This results in a deterministic generation output, which is a bit uninspired when it comes to inference problems; we want a generative language model to be a little creative and nuanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa262c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer).to(\"cuda\"), # making sure all tensors are on cuda. \n",
    "    max_new_tokens = 25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fad67",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tiny vocab for illustrative purposes\n",
    "\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "inverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
       "        1.0120e-04, 3.5758e-01, 4.0122e-03], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# would normally generate these by passing input to a model, but let's pretend we just have them as is. \n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ").to(device)\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a8a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id = torch.argmax(probas).item()\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b27f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_vocab[int(next_token_id)] # had to wrap in int so as to suppress type mismatch error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a79180",
   "metadata": {},
   "source": [
    "The above method (using argmax) is *deterministic*. In other words, the model will always output the exact same token. Below is a sampling based method that has a chance of generating less likely tokens through weighted sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[int(next_token_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1dd34",
   "metadata": {},
   "source": [
    "The generated token changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14c235",
   "metadata": {},
   "source": [
    "We can also repeat this process many times (should see the proba distribution replicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 x closer\n",
      "1 x every\n",
      "0 x effort\n",
      "603 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "336 x toward\n",
      "6 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits : Tensor, temperature, device):\n",
    "    logits.to(device) # making sure tensors are on the same device\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdedbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
       "         1.0120e-04, 3.5758e-01, 4.0122e-03], device='cuda:0'),\n",
       " tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
       "         2.9718e-38, 9.0133e-03, 2.8514e-22], device='cuda:0'),\n",
       " tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "# temperatures are applied before the softmax procedure. Low temperatures (close to 0) will sharpen the peaks (less random choices). High temperatures will smooth out the distribution (more random choices)\n",
    "\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T, device) for T in temperatures]\n",
    "scaled_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32167770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the distributions \n",
    "\n",
    "x = torch.arange(len(vocab)) # matplotlib (and by extension numpy) ONLY WORK WITH CPU MEMORY, and as such, cannot parse tensors that live on the GPU. This means that for plotting purposes, these tensors must be migrated to the CPU (or initialized there to begin with)\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i].cpu(), bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "    # put scaled_probas[i] onto the CPU otherwise error\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ff54d",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dd471",
   "metadata": {},
   "source": [
    "Top k sampling selects the top k highest logits in our output tensor, and mask any other logits by setting them to -inf. When softmax is applied, probabilities are generated such that only the top-k logits are possible (because all other logits go to 0 probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690e7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.7500, 6.2800, 4.5100], device='cuda:0') tensor([3, 7, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ").to(device)\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(top_logits, top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5c5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition= next_token_logits < top_logits[-1], # wherever a logit is lower than the last logit in the top k list, mask.\n",
    "    input = torch.tensor(float(\"-inf\")),\n",
    "    other = next_token_logits\n",
    ")\n",
    "\n",
    "new_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12bb0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(new_logits, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a578e",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134943f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            new_logits = torch.where(\n",
    "                condition= logits < top_logits[:, -1], # wherever a logit is lower than the last logit in the top k list, mask.\n",
    "                input = torch.tensor(float(\"-inf\")),\n",
    "                other = logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        else:\n",
    "            # greedy sampling\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  \n",
    "\n",
    "        # If we can teach an LLM to use the EOS (end of sequence) token, it can generate shorter answers if they are more optimal, saving time and money\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  \n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f57e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton\n"
     ]
    }
   ],
   "source": [
    "# default (same output as before)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    # top_k=25,\n",
    "    # temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5748576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as studio were, his pictures tooenez. \" Granted_> with equanimity. Victor Grindle was; lou flashfor\n"
     ]
    }
   ],
   "source": [
    "# new and improved\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=5,\n",
    "    temperature=1.005\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30ec88",
   "metadata": {},
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31729eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839fcf2",
   "metadata": {},
   "source": [
    "check [testing_load_small_model.ipynb](testing_load_small_model.ipynb) to see loading the small model in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6410b9",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.20.0\n",
      "tqdm version 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bfef46",
   "metadata": {},
   "source": [
    "trying to just grab sebastians method directly from the file to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecafda3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\siddh\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\LLMs-from-scratch-GPU-enabled\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\LLMs-from-scratch-GPU-enabled\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_load_gpt2\u001b[39m(model_size, models_dir):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Validate model size\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\LLMs-from-scratch-GPU-enabled\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\siddh\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\LLMs-from-scratch-GPU-enabled\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\siddh\\Desktop\\SJSU\\F2025\\Learning\\Thesis\\LLMs-from-scratch\\LLMs-from-scratch-GPU-enabled\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
    "# Source for \"Build a Large Language Model From Scratch\"\n",
    "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
    "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path, backup_url)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def download_file(url, destination, backup_url=None):\n",
    "    def _attempt_download(download_url):\n",
    "        response = requests.get(download_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size and file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return True\n",
    "\n",
    "        block_size = 1024  # 1 KB\n",
    "        desc = os.path.basename(download_url)\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
    "            with open(destination, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=block_size):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        if _attempt_download(url):\n",
    "            return\n",
    "    except requests.exceptions.RequestException:\n",
    "        if backup_url is not None:\n",
    "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
    "            try:\n",
    "                if _attempt_download(backup_url):\n",
    "                    return\n",
    "            except requests.exceptions.RequestException:\n",
    "                pass\n",
    "\n",
    "        error_message = (\n",
    "            f\"Failed to download from both primary URL ({url})\"\n",
    "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
    "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
    "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
    "        )\n",
    "        print(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Alternative way using `requests`\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8500025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
